{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6376419e",
   "metadata": {},
   "source": [
    "# 实验任务二：使用CNN来进行图像分类\n",
    "## CIFAR-10 数据集\n",
    "本次实验使用CIFAR-10 数据集来进行实验。\n",
    "CIFAR-10 数据集包含 60,000 张 32×32 像素的彩色图像，\n",
    "分为 10 个类别，每个类别有 6,000 张图像。\n",
    "具体类别包括飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船和卡车。\n",
    "数据集被分为训练集和测试集，\n",
    "其中训练集包含 50,000 张图像，测试集包含 10,000 张图像。\n",
    "## CNN图像分类任务\n",
    "本次任务要求补全代码中空缺部分，包括实现一个CNN类，以及训练过程代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7434d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81602cb6",
   "metadata": {},
   "source": [
    "导入CIFAR-10数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd51464",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# 下载并加载训练集\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# 创建数据加载器\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c307b5",
   "metadata": {},
   "source": [
    "定义CNN网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c80fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        #此处实现模型结构\n",
    "        #TODO\n",
    "        #TODO\n",
    "        #TODO\n",
    "        #TODO\n",
    "        #TODO\n",
    "\n",
    "    def forward(self, x):\n",
    "        #此处实现模型前向传播\n",
    "        #TODO\n",
    "        #TODO\n",
    "        #TODO\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c555e410",
   "metadata": {},
   "source": [
    "进行训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47923b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, device):\n",
    "    num_epochs = 15\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            #实现训练部分，完成反向传播过程\n",
    "            #TODO\n",
    "            #TODO\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:  # 每100个batch打印一次损失\n",
    "                print(\n",
    "                    f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # 每个epoch结束后在测试集上评估模型\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                #补全预测部分代码，输出模型正确率\n",
    "                #TODO\n",
    "                #TODO\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f'Test Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e70fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#创建模型\n",
    "model = SimpleCNN().to(device)\n",
    "train(model, trainloader, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8d7195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(tensor):\n",
    "    # 输入是归一化后的张量 [C, H, W]\n",
    "    # 反归一化：(tensor * std) + mean\n",
    "    # 原始归一化参数：mean=0.5, std=0.5\n",
    "    return tensor * 0.5 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6983f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(trainloader)\n",
    "images, labels = next(data_iter)  # 获取第一个batch\n",
    "\n",
    "# 反归一化并转换为numpy\n",
    "img = denormalize(images[0]).numpy()  # 取batch中的第一张\n",
    "img = np.transpose(img, (1, 2, 0))    # 从(C, H, W)转为(H, W, C)\n",
    "\n",
    "# 显示图像\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Label: {trainset.classes[labels[0]]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c654c8e",
   "metadata": {},
   "source": [
    "## 思考题（可选做）：\n",
    "在实验二中我们实现了在MINST数据集上进行分类，使用本节的CNN又该如何实现，结合本节内容以及实验二内容尝试实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f37e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
